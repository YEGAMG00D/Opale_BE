package yegam.opale_be.global.openai;

import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.*;
import org.springframework.stereotype.Component;
import org.springframework.web.client.RestTemplate;

import java.util.*;

@Component
@RequiredArgsConstructor
@Slf4j
public class OpenAiClient {

  private final RestTemplate restTemplate;
  private final ObjectMapper objectMapper = new ObjectMapper();

  // ğŸ”¥ Vision + ì´ë¯¸ì§€ ì…ë ¥ ê°€ëŠ¥í•œ ê³µì‹ ì—”ë“œí¬ì¸íŠ¸
  private static final String OPENAI_URL = "https://api.openai.com/v1/responses";

  @Value("${openai.api-key}")
  private String apiKey;

  public Map<String, String> requestOcr(String prompt, String base64Image) {

    try {
      // 1) Vision ë©”ì‹œì§€ í¬ë§· êµ¬ì„±
      Map<String, Object> userMessage = new HashMap<>();
      List<Object> contentList = new ArrayList<>();

      // ğŸ”¹ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
      contentList.add(Map.of(
          "type", "text",
          "text", prompt
      ));

      // ğŸ”¹ ì´ë¯¸ì§€(base64)
      contentList.add(Map.of(
          "type", "image_url",
          "image_url", Map.of(
              "url", "data:image/png;base64," + base64Image
          )
      ));

      userMessage.put("role", "user");
      userMessage.put("content", contentList);

      // 2) request body â€” â˜… Responses API ì „ìš©
      Map<String, Object> body = new HashMap<>();
      body.put("model", "gpt-4o-mini");         // Vision ì§€ì› ëª¨ë¸
      body.put("input", List.of(userMessage));  // Chat-like ë°©ì‹ì€ messages â†’ ResponsesëŠ” input

      String jsonBody = objectMapper.writeValueAsString(body);

      log.warn("ğŸ“¤ [OpenAI Request JSON] {}", jsonBody);

      // 3) í—¤ë”
      HttpHeaders headers = new HttpHeaders();
      headers.setContentType(MediaType.APPLICATION_JSON);
      headers.setAccept(List.of(MediaType.APPLICATION_JSON));
      headers.setBearerAuth(apiKey);
      headers.set("User-Agent", "Opale-SpringBoot");

      HttpEntity<String> request = new HttpEntity<>(jsonBody, headers);

      // 4) ìš”ì²­ ë³´ë‚´ê¸°
      ResponseEntity<String> responseEntity =
          restTemplate.exchange(OPENAI_URL, HttpMethod.POST, request, String.class);

      String response = responseEntity.getBody();
      log.warn("ğŸ“¥ [OpenAI Response JSON] {}", response);

      // 5) ì‘ë‹µ íŒŒì‹±
      Map<String, Object> json = objectMapper.readValue(response, Map.class);

      List<Map<String, Object>> outputs = (List<Map<String, Object>>) json.get("output_text");
      String content = outputs.get(0).toString();  // ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ì‘ë‹µ

      // GPTê°€ ì¤€ JSON ë¬¸ìì—´ â†’ Map ë³€í™˜
      return objectMapper.readValue(content, Map.class);

    } catch (Exception e) {
      log.error("âŒ OCR API í˜¸ì¶œ ì‹¤íŒ¨", e);
      throw new RuntimeException("OpenAI Vision OCR í˜¸ì¶œ ì‹¤íŒ¨");
    }
  }
}
